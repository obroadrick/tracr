{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99FBiGH7bsfn"
      },
      "source": [
        "# Training Compiled Models\n",
        "\n",
        "This notebook contains Oliver's in-development code for *training* a compiled model; might we observe the unlearning phenomenon? (This notebook is adapted from `examples/Visualize_Tracr_Models.ipynb`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qm-PM1PEawCx"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import jax\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "jax.config.update('jax_default_matmul_precision', 'float32') # The default of float16 can lead to discrepancies between outputs of the compiled model and the RASP program.\n",
        "from tracr.compiler import compiling\n",
        "from tracr.compiler import lib\n",
        "from tracr.rasp import rasp\n",
        "import jax.numpy as jnp             # Oliver added\n",
        "import optax                        # Oliver added\n",
        "import haiku as hk                  # Oliver added\n",
        "import copy                         # Oliver added\n",
        "import random                       # Oliver added\n",
        "import json                         # Oliver added\n",
        "seed = 3141592 + 3                  # Oliver added\n",
        "random.seed(seed)                   # Oliver added\n",
        "np.random.seed(seed)                # Oliver added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "8hV0nv_ISmhM"
      },
      "outputs": [],
      "source": [
        "#@title Define RASP programs\n",
        "def get_program(program_name, max_seq_len):\n",
        "  \"\"\"Returns RASP program and corresponding token vocabulary.\"\"\"\n",
        "  if program_name == \"length\":\n",
        "    vocab = {\"a\", \"b\", \"c\", \"d\"}\n",
        "    program = lib.make_length()\n",
        "  elif program_name == \"frac_prevs\":\n",
        "    vocab = {\"a\", \"b\", \"c\", \"x\"}\n",
        "    program = lib.make_frac_prevs((rasp.tokens == \"x\").named(\"is_x\"))\n",
        "  elif program_name == \"dyck-2\":\n",
        "    vocab = {\"(\", \")\", \"{\", \"}\"}\n",
        "    program = lib.make_shuffle_dyck(pairs=[\"()\", \"{}\"])\n",
        "  elif program_name == \"dyck-3\":\n",
        "    vocab = {\"(\", \")\", \"{\", \"}\", \"[\", \"]\"}\n",
        "    program = lib.make_shuffle_dyck(pairs=[\"()\", \"{}\", \"[]\"])\n",
        "  elif program_name == \"sort\":\n",
        "    vocab = {1, 2, 3, 4, 5}\n",
        "    program = lib.make_sort(\n",
        "        rasp.tokens, rasp.tokens, max_seq_len=max_seq_len, min_key=1)\n",
        "  elif program_name == \"sort_unique\":\n",
        "    vocab = {1, 2, 3, 4, 5}\n",
        "    program = lib.make_sort_unique(rasp.tokens, rasp.tokens)\n",
        "  elif program_name == \"hist\":\n",
        "    vocab = {\"a\", \"b\", \"c\", \"d\"}\n",
        "    program = lib.make_hist()\n",
        "  elif program_name == \"sort_freq\":\n",
        "    vocab = {\"a\", \"b\", \"c\", \"d\"}\n",
        "    program = lib.make_sort_freq(max_seq_len=max_seq_len)\n",
        "  elif program_name == \"pair_balance\":\n",
        "    vocab = {\"(\", \")\"}\n",
        "    program = lib.make_pair_balance(\n",
        "        sop=rasp.tokens, open_token=\"(\", close_token=\")\")\n",
        "  else:\n",
        "    raise NotImplementedError(f\"Program {program_name} not implemented.\")\n",
        "  return program, vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L_m_ufaua9ri"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Program: sort\n",
            "   Input vocabulary: {1, 2, 3, 4, 5}\n",
            "   Context size: 5\n"
          ]
        }
      ],
      "source": [
        "#@title: Assemble model\n",
        "program_name = \"sort\"  #@param [\"length\", \"frac_prevs\", \"dyck-2\", \"dyck-3\", \"sort\", \"sort_unique\", \"hist\", \"sort_freq\", \"pair_balance\"]\n",
        "SORT_MAX = 5  #@param {label: \"Test\", type: \"integer\"} # largest number in the vocab\n",
        "\n",
        "program, vocab = get_program(program_name=program_name,\n",
        "                             max_seq_len=SORT_MAX)\n",
        "\n",
        "print(f\"   Program: {program_name}\")\n",
        "print(f\"   Input vocabulary: {vocab}\")\n",
        "print(f\"   Context size: {SORT_MAX}\")\n",
        "\n",
        "assembled_model = compiling.compile_rasp_to_model(\n",
        "      program=program,\n",
        "      vocab=vocab,\n",
        "      max_seq_len=SORT_MAX,\n",
        "      causal=False,# aha\n",
        "      compiler_bos=\"bos\",\n",
        "      compiler_pad=\"pad\",\n",
        "      mlp_exactness=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bos', 1, 5, 5, 4] ['bos', 1, 4, 5, 5] ['bos', 1, 4, 5, 5]\n",
            "['bos', 5, 3, 1, 3] ['bos', 1, 3, 3, 5] ['bos', 1, 3, 3, 5]\n",
            "['bos', 5, 2, 1, 1] ['bos', 1, 1, 2, 5] ['bos', 1, 1, 2, 5]\n"
          ]
        }
      ],
      "source": [
        "# GENERATE A DATASET FOR TRAINING THE COMPILED MODEL\n",
        "instance_lengths = 4\n",
        "dataset_size = 10000\n",
        "train_x = [[\"bos\"]+random.choices(range(1,SORT_MAX+1),k=instance_lengths) for i in range(dataset_size)]\n",
        "train_y = [[\"bos\"]+sorted(x[1:]) for x in train_x]\n",
        "dataset_size = 100\n",
        "val_x = [[\"bos\"]+random.choices(range(1,SORT_MAX+1),k=instance_lengths) for i in range(dataset_size)]\n",
        "val_y = [[\"bos\"]+sorted(x[1:]) for x in val_x]\n",
        "dataset_size = 100\n",
        "test_x = [[\"bos\"]+random.choices(range(1,SORT_MAX+1),k=instance_lengths) for i in range(dataset_size)]\n",
        "test_y = [[\"bos\"]+sorted(x[1:]) for x in test_x]\n",
        "# Confirm that the compiled model correctly solves the first few dataset instances\n",
        "for i in range(3):\n",
        "    print(train_x[i], train_y[i], assembled_model.apply(train_x[i]).decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BEFORE PERTURBATION\n",
            "x: ['bos', 1, 3, 2, 1]\n",
            "output: ['bos', 1, 1, 2, 3]\n",
            "(1, 1, 5, 5)\n",
            "(1, 5, 50)\n",
            "AFTER PERTURBATION:\n",
            "x: ['bos', 1, 3, 2, 1]\n",
            "output: ['bos', 1, 1, 2, 3]\n",
            "(1, 5, 50)\n",
            "(1, 5)\n"
          ]
        }
      ],
      "source": [
        "# PERTURB THE PARAMETERS\n",
        "PERTURBATION_FACTOR = 0 # if zero, the no perturbation; otherwise, order 10**(-3) seems to give a reasonable range\n",
        "x = [\"bos\", 1,3,2,1]\n",
        "print('BEFORE PERTURBATION')\n",
        "out = assembled_model.apply(x)\n",
        "print('x:',x)\n",
        "print('output:',out.decoded)\n",
        "print(out.attn_logits[0].shape)\n",
        "print(out.transformer_output.shape)\n",
        "\n",
        "# Construct/sample a small perturbation (for now, uniformly random reals in a small interval, e.g. [-.01, .01])\n",
        "perturbation = copy.deepcopy(assembled_model.params)\n",
        "for key in perturbation.keys():\n",
        "    for key2 in perturbation[key].keys():\n",
        "        perturbation[key][key2] = (np.random.rand(*perturbation[key][key2].shape) - .5) * PERTURBATION_FACTOR #np.zeros_like(perturbation[key][key2])#\n",
        "# print(assembled_model.params['transformer/layer_2/attn/query']['w']) # Check before perturb\n",
        "\n",
        "# Perturb model parameters\n",
        "for key in assembled_model.params.keys():\n",
        "    for key2 in assembled_model.params[key].keys():\n",
        "        assembled_model.params[key][key2] += perturbation[key][key2]\n",
        "# print(assembled_model.params['transformer/layer_2/attn/query']['w']) # Check after perturb\n",
        "\n",
        "print('AFTER PERTURBATION:')\n",
        "out = assembled_model.apply(x)\n",
        "print('x:',x)\n",
        "print('output:',out.decoded)\n",
        "print(out.transformer_output.shape)\n",
        "print(out.unembedded.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# PLOT THE PER-TOKEN OUTPUT DISTRIBUTIONS OVER THE VOCABULARY\n",
        "x = ['bos',3,1,5,4]\n",
        "raw_dists = copy.deepcopy(assembled_model.apply(x).raw_token_dists[0,1:,:]) #B,T,V\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(raw_dists)\n",
        "ax.set(xlabel='vocab index',ylabel='token index',title='raw per token distributions')\n",
        "ax.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Program: sort\n",
            "   Input vocabulary: {1, 2, 3, 4, 5}\n",
            "   Context size: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0 0.904871940612793\n",
            "1.0 0.9012876135110856\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(val_loss, fp)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Perform a training step\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m params, opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(params, opt_state, x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(params, opt_state, x, y):\n\u001b[0;32m---> 14\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state, params)\n\u001b[1;32m     16\u001b[0m     params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params, updates)\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:621\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    619\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 621\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:691\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 691\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    694\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/api.py:2176\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2175\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2176\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2177\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:143\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(traceable, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    142\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 143\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:132\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    131\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 132\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/profiler.py:335\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:777\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[38;5;241m=\u001b[39mcurrent_name_stack) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[1;32m    776\u001b[0m   fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 777\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    779\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun, env\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/jax/_src/linear_util.py:192\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
            "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(params, x, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(params, x, y):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Standard softmax cross entropy loss.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mraw_token_dists[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m:,:]                    \u001b[38;5;66;03m# has shape [T-1, V] where T is sequence lenght and V is vocab size (T-1 because we don't train for the bos token)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     y_indices \u001b[38;5;241m=\u001b[39m assembled_model\u001b[38;5;241m.\u001b[39minput_encoder\u001b[38;5;241m.\u001b[39mencode(y)[\u001b[38;5;241m1\u001b[39m:]         \u001b[38;5;66;03m# maps the ground truth y output tokens to their vocab indices (skips the bos token)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     y \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(y_indices, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])                 \u001b[38;5;66;03m# get the one-hot encoding of the ground truth indices\u001b[39;00m\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/compiler/assemble.py:76\u001b[0m, in \u001b[0;36mAssembledTransformerModel.functional_apply\u001b[0;34m(self, external_params, tokens)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunctional_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, external_params, tokens: List[bases\u001b[38;5;241m.\u001b[39mValue]):\u001b[38;5;66;03m# -> AssembledTransformerModelOutput:\u001b[39;00m\n\u001b[1;32m     75\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m external_params\n\u001b[0;32m---> 76\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/compiler/assemble.py:84\u001b[0m, in \u001b[0;36mAssembledTransformerModel.apply\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     82\u001b[0m tokens \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39marray([tokens])\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print('benjie',tokens)\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# print('don\\'t forget me:',output.transformer_output.output) # also is here!\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# print('HERE WE ARE:',type(output))\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# print(type(output.transformer_output))\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# print(output.transformer_output.output.shape)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m decoded \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39munembedded_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/multi_transform.py:314\u001b[0m, in \u001b[0;36mwithout_apply_rng.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fn\u001b[39m(params, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   check_rng_kwarg(kwargs)\n\u001b[0;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/transform.py:183\u001b[0m, in \u001b[0;36mwithout_state.<locals>.apply_fn\u001b[0;34m(params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    177\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    178\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaiku transform adds three arguments (params, state, rng) to apply. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    179\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf the functions you are transforming use the same names you must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass them positionally (e.g. `f.apply(.., my_state)` and not by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname (e.g. `f.apply(.., state=my_state)`)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 183\u001b[0m out, state \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    185\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m base\u001b[38;5;241m.\u001b[39mNonEmptyStateError(\n\u001b[1;32m    186\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` then use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hk.transform_with_state`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/transform.py:456\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.apply_fn\u001b[0;34m(params, state, rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(params\u001b[38;5;241m=\u001b[39mparams, state\u001b[38;5;241m=\u001b[39mstate, rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/compiler/assemble.py:292\u001b[0m, in \u001b[0;36massemble_craft_model.<locals>.forward\u001b[0;34m(emb)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;129m@hk\u001b[39m\u001b[38;5;241m.\u001b[39mwithout_apply_rng\n\u001b[1;32m    289\u001b[0m \u001b[38;5;129m@hk\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(emb):\n\u001b[1;32m    291\u001b[0m   compiled_model \u001b[38;5;241m=\u001b[39m get_compiled_model()\n\u001b[0;32m--> 292\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/transformer/model.py:203\u001b[0m, in \u001b[0;36mCompiledTransformerModel.__call__\u001b[0;34m(self, tokens, use_dropout)\u001b[0m\n\u001b[1;32m    200\u001b[0m   input_mask \u001b[38;5;241m=\u001b[39m (tokens \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token)\n\u001b[1;32m    201\u001b[0m input_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(tokens)\n\u001b[0;32m--> 203\u001b[0m transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# print('OHOHOHOHOHOHOHOHOH')\u001b[39;00m\n\u001b[1;32m    209\u001b[0m fully_unembedded, logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munembed(\n\u001b[1;32m    210\u001b[0m         transformer_output\u001b[38;5;241m.\u001b[39moutput,\n\u001b[1;32m    211\u001b[0m         use_unembed_argmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_unembed_argmax,\n\u001b[1;32m    212\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/transformer/model.py:129\u001b[0m, in \u001b[0;36mTransformer.__call__\u001b[0;34m(self, embeddings, mask, use_dropout)\u001b[0m\n\u001b[1;32m    122\u001b[0m attn_block \u001b[38;5;241m=\u001b[39m attention\u001b[38;5;241m.\u001b[39mMultiHeadAttention(\n\u001b[1;32m    123\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m    124\u001b[0m     key_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mkey_size,\n\u001b[1;32m    125\u001b[0m     model_size\u001b[38;5;241m=\u001b[39mmodel_size,\n\u001b[1;32m    126\u001b[0m     w_init\u001b[38;5;241m=\u001b[39minitializer,\n\u001b[1;32m    127\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    128\u001b[0m attn_in \u001b[38;5;241m=\u001b[39m layer_norm(residual)\n\u001b[0;32m--> 129\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[43mattn_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m attn_out, attn_logits \u001b[38;5;241m=\u001b[39m attn_out\u001b[38;5;241m.\u001b[39mout, attn_out\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dropout_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:464\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__call__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    462\u001b[0m     f \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mmethod_name)\n\u001b[0;32m--> 464\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:305\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 305\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    309\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method,\n\u001b[1;32m    310\u001b[0m                     orig_class\u001b[38;5;241m=\u001b[39morig_class)\n\u001b[1;32m    311\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/transformer/attention.py:126\u001b[0m, in \u001b[0;36mMultiHeadAttention.__call__\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Compute key/query/values (overload K/Q/V to denote the respective sizes).\u001b[39;00m\n\u001b[1;32m    125\u001b[0m query_heads \u001b[38;5;241m=\u001b[39m projection(query, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# [T', H, Q=K]\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m key_heads \u001b[38;5;241m=\u001b[39m \u001b[43mprojection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [T, H, K]\u001b[39;00m\n\u001b[1;32m    127\u001b[0m value_heads \u001b[38;5;241m=\u001b[39m projection(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_size, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# [T, H, V]\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Compute attention weights.\u001b[39;00m\n",
            "File \u001b[0;32m/scratch/oliver/tracr/tracr/transformer/attention.py:161\u001b[0m, in \u001b[0;36mMultiHeadAttention._linear_projection\u001b[0;34m(self, x, head_size, name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;129m@hk\u001b[39m\u001b[38;5;241m.\u001b[39mtransparent\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_linear_projection\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m     name: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    160\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m jnp\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 161\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mhk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mhead_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mw_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m(x)\n\u001b[1;32m    162\u001b[0m   \u001b[38;5;241m*\u001b[39mleading_dims, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    163\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m*\u001b[39mleading_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, head_size))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/module.py:141\u001b[0m, in \u001b[0;36mModuleMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# We populate _auto_repr before `__init__` to allow `repr(self)` during the\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# constructor of the module.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (config\u001b[38;5;241m.\u001b[39mget_config()\u001b[38;5;241m.\u001b[39mmodule_auto_repr \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTO_REPR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)):\n\u001b[0;32m--> 141\u001b[0m   module_repr \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m   module_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m(module)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/haiku/_src/utils.py:73\u001b[0m, in \u001b[0;36mauto_repr\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Keep used kwargs in the order they appear in argspec.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m arg_names\u001b[38;5;241m.\u001b[39mextend(n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m kwargs)\n\u001b[0;32m---> 73\u001b[0m arg_values \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcallargs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=deprecated-method\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Extract default parameter values.\u001b[39;00m\n\u001b[1;32m     76\u001b[0m defaults \u001b[38;5;241m=\u001b[39m argspec\u001b[38;5;241m.\u001b[39mdefaults \u001b[38;5;129;01mor\u001b[39;00m ()\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/inspect.py:1493\u001b[0m, in \u001b[0;36mgetcallargs\u001b[0;34m(func, *positional, **named)\u001b[0m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetcallargs\u001b[39m(func, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39mpositional, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnamed):\n\u001b[1;32m   1488\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get the mapping of arguments to values.\u001b[39;00m\n\u001b[1;32m   1489\u001b[0m \n\u001b[1;32m   1490\u001b[0m \u001b[38;5;124;03m    A dict is returned, with keys the function argument names (including the\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;124;03m    names of the * and ** arguments, if any), and values the respective bound\u001b[39;00m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;124;03m    values from 'positional' and 'named'.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1493\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mgetfullargspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m     args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults, ann \u001b[38;5;241m=\u001b[39m spec\n\u001b[1;32m   1495\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/inspect.py:1277\u001b[0m, in \u001b[0;36mgetfullargspec\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get the names and default values of a callable object's parameters.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \n\u001b[1;32m   1247\u001b[0m \u001b[38;5;124;03mA tuple of seven things is returned:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;124;03m  - wrapper chains defined by __wrapped__ *not* unwrapped automatically\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;66;03m# Re: `skip_bound_arg=False`\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;66;03m# getfullargspec() historically ignored __wrapped__ attributes,\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;66;03m# so we ensure that remains the case in 3.3+\u001b[39;00m\n\u001b[0;32m-> 1277\u001b[0m     sig \u001b[38;5;241m=\u001b[39m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m# Most of the times 'signature' will raise ValueError.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;66;03m# But, it can also raise AttributeError, and, maybe something\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;66;03m# else. So to be fully backwards compatible, we catch all\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# possible exceptions here, and reraise a TypeError.\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported callable\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/inspect.py:2463\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2458\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[1;32m   2460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isfunction(obj) \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[0;32m-> 2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msigcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2464\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mskip_bound_arg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_bound_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n\u001b[1;32m   2468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_builtin(sigcls, obj,\n\u001b[1;32m   2469\u001b[0m                                    skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg)\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/inspect.py:2334\u001b[0m, in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2332\u001b[0m kind \u001b[38;5;241m=\u001b[39m _POSITIONAL_ONLY \u001b[38;5;28;01mif\u001b[39;00m posonly_left \u001b[38;5;28;01melse\u001b[39;00m _POSITIONAL_OR_KEYWORD\n\u001b[1;32m   2333\u001b[0m annotation \u001b[38;5;241m=\u001b[39m annotations\u001b[38;5;241m.\u001b[39mget(name, _empty)\n\u001b[0;32m-> 2334\u001b[0m parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[43mParameter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2335\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2336\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[43m[\u001b[49m\u001b[43moffset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m posonly_left:\n\u001b[1;32m   2338\u001b[0m     posonly_left \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/inspect.py:2639\u001b[0m, in \u001b[0;36mParameter.__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, kind, \u001b[38;5;241m*\u001b[39m, default\u001b[38;5;241m=\u001b[39m_empty, annotation\u001b[38;5;241m=\u001b[39m_empty):\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kind \u001b[38;5;241m=\u001b[39m \u001b[43m_ParameterKind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2641\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid Parameter.kind\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/space/oliver/miniconda3/envs/rasp/lib/python3.10/enum.py:359\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    classes/types should always be True.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, qualname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m    `type`, if set, will be mixed in as the first base class.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# simple value lookup\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# All the code below depends on using this function f as the model...  :/\n",
        "f = assembled_model.functional_apply\n",
        "\n",
        "# B=1 for now... (did I cause that or was it already like that?) TODO figure this out\n",
        "def loss_fn(params, x, y):\n",
        "    # Standard softmax cross entropy loss.\n",
        "    logits = f(params,x).raw_token_dists[0,1:,:]                    # has shape [T-1, V] where T is sequence lenght and V is vocab size (T-1 because we don't train for the bos token)\n",
        "    y_indices = assembled_model.input_encoder.encode(y)[1:]         # maps the ground truth y output tokens to their vocab indices (skips the bos token)\n",
        "    y = jax.nn.one_hot(y_indices, logits.shape[-1])                 # get the one-hot encoding of the ground truth indices\n",
        "    return -jnp.sum(y * jax.nn.log_softmax(logits)) / y.shape[0]    # compute and return the (average) cross entropy loss\n",
        "\n",
        "# Can't jit this because of string input/output... TODO make numbers\n",
        "def train_step(params, opt_state, x, y):\n",
        "    grads = jax.grad(loss_fn)(params, x, y)\n",
        "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
        "    params = optax.apply_updates(params, updates)\n",
        "    return params, opt_state\n",
        "\n",
        "def eval(params, data_x, data_y):\n",
        "    \"\"\" computes the average loss and accuracy of the function given by the passed params on the dataset data_x,data_y\"\"\"\n",
        "    total_acc, total_loss = 0, 0\n",
        "    for x,y in zip(data_x,data_y): #TODO batch not 1 by 1\n",
        "        # TODO no need to forward pass twice (once for loss and once for accuracy)\n",
        "        total_loss += float(loss_fn(params, x, y))\n",
        "        y_pred = f(params,x).decoded\n",
        "        total_acc += len([i for i, (y_pred, y) in enumerate(zip(y_pred, y)) if y_pred == y]) / len(y)\n",
        "    return total_acc / len(data_x), total_loss / len(data_x)\n",
        "\n",
        "# Experiment organization\n",
        "expdir = '/space/oliver/tracr/tracr/experiments/' + '2024_sep_05_initial_experiments_2/'\n",
        "val_acc_path = expdir + 'val_acc'\n",
        "val_loss_path = expdir + 'val_loss'\n",
        "# Save experimental details\n",
        "lr = 1e-7\n",
        "optimization_algorithm = 'sgd'\n",
        "task = program_name\n",
        "vocab = vocab\n",
        "instance_lengths = instance_lengths\n",
        "print(f\"   Program: {program_name}\")\n",
        "print(f\"   Input vocabulary: {vocab}\")\n",
        "print(f\"   Context size: {SORT_MAX}\")\n",
        "# TODO TODO continue from here with the logging....\n",
        "# TODO TODO continue from here with the logging....\n",
        "# TODO TODO continue from here with the logging....\n",
        "# TODO TODO continue from here with the logging....\n",
        "# TODO TODO continue from here with the logging....\n",
        "\n",
        "# Training loop\n",
        "params = copy.deepcopy(assembled_model.params) # Initialize training from the perfect-accuracy parameters \n",
        "optimizer = optax.sgd(learning_rate=lr)\n",
        "opt_state = optimizer.init(params)\n",
        "val_acc, val_loss = [], []\n",
        "VAL_FREQ = 100\n",
        "for i, (x, y) in enumerate(zip(train_x,train_y)):\n",
        "    # Validate every VAL_FREQ steps\n",
        "    if i % VAL_FREQ == 0:\n",
        "        acc, loss = eval(params, val_x, val_y)\n",
        "        print(acc, loss)\n",
        "        val_acc.append(acc)\n",
        "        val_loss.append(loss)\n",
        "        #save valacc andl sss\n",
        "        with open(val_acc_path, \"w\") as fp:\n",
        "            json.dump(val_acc, fp)\n",
        "        with open(val_loss_path, \"w\") as fp:\n",
        "            json.dump(val_loss, fp)\n",
        "    # Perform a training step\n",
        "    params, opt_state = train_step(params, opt_state, x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PRINT VALIDATION LOSS AND ACCURACY CURVES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GARBAGE OLD CODE\n",
        "# // ASSORTED DEBUGGING CODE\n",
        "# print('So we have a compiled model for sorting:',assembled_model.model_config)\n",
        "# print('x',x)\n",
        "# print('out.decoded',out.decoded)\n",
        "# # print('out.transformer_output.shape',out.transformer_output.shape)\n",
        "# # print('out.unembedded[0]',out.unembedded[0])\n",
        "# # print('out.attn_logits[-1].shape',out.attn_logits[-1].shape)\n",
        "# # print('len(out.residuals)',len(out.residuals))\n",
        "# # print('len(out.layer_outputs)',len(out.layer_outputs))\n",
        "# # print('out.layer_outputs[-1].shape',out.layer_outputs[-1].shape)\n",
        "# print('Among the many things in `out` we now have the following raw_token_dists...')\n",
        "# print('out.raw_token_dists.shape',out.raw_token_dists.shape)\n",
        "# print('out.raw_token_dists',out.raw_token_dists)\n",
        "# print('Sanity check: can we decode from them manually?')\n",
        "# raw_dists = out.raw_token_dists[0,:,:]\n",
        "# # print(raw_dists.shape)\n",
        "# argmaxed_dists = np.argmax(raw_dists,axis=1)\n",
        "# print(argmaxed_dists)\n",
        "# print([assembled_model.input_encoder.bos_token] + assembled_model.output_encoder.decode(argmaxed_dists.tolist())[1:])\n",
        "# assembled_model.params['transformer/layer_0/attn/query']['b'][0]\n",
        "# out = f.apply(initial_params,None,['bos',3,1,2])\n",
        "# out.raw_token_dists.shape\n",
        "# x,y = ['bos',3,1],['bos',1,3]\n",
        "# params = train_step(params, opt_state, x, y)\n",
        "# x, y = dataset_x[0], dataset_y[0]\n",
        "# x,y = ['bos',3,1],['bos',1,3]\n",
        "# print(x,y)\n",
        "# loss_fn(initial_params,x,y)\n",
        "# # What if we look at out.transformer_output?\n",
        "# outs = out.transformer_output[0,:,:]\n",
        "# print('out.transformer_output.shape',out.transformer_output.shape)\n",
        "# embeddings = assembled_model.params['token_embed']['embeddings'].transpose()\n",
        "# print('assembled_model.params.keys()',assembled_model.params.keys())\n",
        "# print('outs.shape',outs.shape)\n",
        "# print('tok_embeddings.shape',embeddings.shape)\n",
        "# # pos_embeddings = assembled_model.params['pos_embed']['embeddings'].transpose()\n",
        "# # print('pos_embeddings.shape',pos_embeddings.shape)\n",
        "# distsmaybe = outs @ embeddings\n",
        "# # pos_something = outs @ pos_embeddings\n",
        "# print('distsmaybe',distsmaybe)\n",
        "# # print('pos_something',pos_something)\n",
        "# print('input x:',x)\n",
        "# print('pretend output (undecoded):',np.argmax(distsmaybe,axis=1))\n",
        "# print('pretend output (decoded):',assembled_model.input_encoder.decode(np.argmax(distsmaybe,axis=1)))\n",
        "\n",
        "# model_config, module_names = _get_model_config_and_module_names(craft_model)\n",
        "# model_config.causal = causal\n",
        "# residual_space = bases.join_vector_spaces(craft_model.residual_space, tokens_space, indices_space, output_space)\n",
        "# res_to_out = vectorspace_fns.project(residual_space, output_space)\n",
        "# print(type(assembled_model.get_compiled_model()))# no need for that\n",
        "# let's just try argmaxing this thing\n",
        "# maybe it's actually logit like\n",
        "# def unembed(x):\n",
        "#     out = x @ res_to_out.matrix\n",
        "#     return jnp.argmax(out, axis=-1)\n",
        "# out.unembedded\n",
        "# def compute_loss_and_updates(trainable_variables, non_trainable_variables, x, y):\n",
        "#     y_pred, non_trainable_variables = model.stateless_call(\n",
        "#         trainable_variables, non_trainable_variables, x\n",
        "#     )\n",
        "#     loss = loss_fn(y, y_pred)\n",
        "#     return loss, non_trainable_variables\n",
        "\n",
        "# grad_fn = jax.value_and_grad(compute_loss_and_updates, has_aux=True)\n",
        "# (loss, non_trainable_variables), grads = grad_fn(\n",
        "#     trainable_variables, non_trainable_variables, x, y\n",
        "# )\n",
        "\n",
        "# def train_step(state, data):\n",
        "#     trainable_variables, non_trainable_variables, optimizer_variables = state\n",
        "#     x, y = data\n",
        "#     (loss, non_trainable_variables), grads = grad_fn(\n",
        "#         trainable_variables, non_trainable_variables, x, y\n",
        "#     )\n",
        "#     trainable_variables, optimizer_variables = optimizer.stateless_apply(\n",
        "#         grads, trainable_variables, optimizer_variables\n",
        "#     )\n",
        "#     # Return updated state\n",
        "#     return loss, (\n",
        "#         trainable_variables,\n",
        "#         non_trainable_variables,\n",
        "#         optimizer_variables,\n",
        "#     )\n",
        "# Train the compiled model\n",
        "# num_epochs = 10\n",
        "# batch_size = 100\n",
        "# for epoch in range(num_epochs):\n",
        "#     for batch_num in range(math.floor(len(dataset_x) / batch_size)):\n",
        "#         idx = batch_num * batch_size\n",
        "#         x_batch, y_batch = dataset_x[idx:idx+batch_size], dataset_y[idx:idx+batch_size]\n",
        "#         for x in x_batch:\n",
        "#             y_pred = assembled_model.apply(x)\n",
        "#             print(y_pred.decoded)\n",
        "#             # print(len(y_pred.layer_outputs))\n",
        "#             # print(y_pred.layer_outputs[1])\n",
        "#             print(y_pred.transformer_output[1])\n",
        "#             break\n",
        "#         break\n",
        "#     break\n",
        "# return params['transformer/layer_0/attn/query']['b'][0] #testing!!!!\n",
        "# a = f.apply(params,x)\n",
        "# return a[0,0,0]# can we even get a gradient through the returned raw logit things????\n",
        "# return a.params['transformer/layer_0/attn/query']['b'][0]# can we even get a gradient through the returned chex data structure???\n",
        "# print(type(a))\n",
        "# par = copy.deepcopy(assembled_model.params)\n",
        "# dummy_x = train_x[0]\n",
        "# params = f.init(None,dummy_x)\n",
        "# print(params)\n",
        "\n",
        "# figure, ax = plt.subplots(figsize=(10, 8))\n",
        "# line1, = ax.plot(x, y)\n",
        "# val_loss_curve.set_ydata(val_losses)\n",
        "# fig, ax = plt.subplots()\n",
        "# val_loss_curve, = ax.plot([1,23,3,2,2,3,2,3,3,2,32,3,2,32,3,2])\n",
        "# ax.set(xlabel='training steps',ylabel='loss',title='validation loss throughout training')\n",
        "# ax.grid()\n",
        "# plt.ion()\n",
        "# plt.show() \n",
        "\n",
        "# val_loss_curve.set_xdata(range(len(val_losses)))#[i for i in range(len(val_losses))], [i for i in range(len(val_losses))])#val_losses)    # Update plot\n",
        "# val_loss_curve.set_ydata(val_losses)\n",
        "# fig.canvas.draw()\n",
        "# fig.canvas.flush_events()\n",
        "# print('here')\n",
        "# print(val_losses)\n",
        "#print(params)\n",
        "\n",
        "#benjie:\n",
        "# logits = f.apply(params, 0) #f.apply(params,{'pos_embed': {'embeddings': jnp.zeros_like(params['pos_embed']['embeddings'])}})\n",
        "# return logits[\"mystuff\"]\n",
        "# f = hk.without_apply_rng(hk.transform(assembled_model.apply))\n",
        "# fn = assembled_model.apply\n",
        "\n",
        "# def testing(params):\n",
        "#     assembled_model = compiling.compile_rasp_to_model(\n",
        "#       program=program,\n",
        "#       vocab=vocab,\n",
        "#       max_seq_len=max_seq_len,\n",
        "#       causal=False,# aha\n",
        "#       compiler_bos=\"bos\",\n",
        "#       compiler_pad=\"pad\",\n",
        "#       mlp_exactness=100)\n",
        "#     f = hk.without_apply_rng(hk.transform(assembled_model.apply))\n",
        "#     return f.apply(params, 0)\n",
        "\n",
        "# def oliver_testing(x):\n",
        "#     assembled_model = compiling.compile_rasp_to_model(\n",
        "#       program=program,\n",
        "#       vocab=vocab,\n",
        "#       max_seq_len=SORT_MAX,\n",
        "#       causal=False,# aha\n",
        "#       compiler_bos=\"bos\",\n",
        "#       compiler_pad=\"pad\",\n",
        "#       mlp_exactness=100)\n",
        "#     return assembled_model.apply(x)\n",
        "#loss = 0\n",
        "# for (x,y) in zip(val_x,val_y):\n",
        "#     loss += loss_fn(params, x, y)\n",
        "# loss /= len(val_x)\n",
        "# val_losses.append(loss)\n",
        "# print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkEkVcEHa2gf"
      },
      "outputs": [],
      "source": [
        "# PLOTTING FUNCTIONS FROM THE ORIGINAL VERSION OF THIS NOTEBOOK\n",
        "\n",
        "#@title Plotting functions\n",
        "def tidy_label(label, value_width=5):\n",
        "  if ':' in label:\n",
        "    label, value = label.split(':')\n",
        "  else:\n",
        "    value = ''\n",
        "  return label + f\":{value:>{value_width}}\"\n",
        "\n",
        "\n",
        "def add_residual_ticks(model, value_width=5, x=False, y=True):\n",
        "  if y:\n",
        "    plt.yticks(\n",
        "            np.arange(len(model.residual_labels))+0.5, \n",
        "            [tidy_label(l, value_width=value_width)\n",
        "              for l in model.residual_labels], \n",
        "            family='monospace',\n",
        "            fontsize=20,\n",
        "    )\n",
        "  if x:\n",
        "    plt.xticks(\n",
        "            np.arange(len(model.residual_labels))+0.5, \n",
        "            [tidy_label(l, value_width=value_width)\n",
        "              for l in model.residual_labels], \n",
        "            family='monospace',\n",
        "            rotation=90,\n",
        "            fontsize=20,\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_computation_trace(model,\n",
        "                           input_labels,\n",
        "                           residuals_or_outputs,\n",
        "                           add_input_layer=False,\n",
        "                           figsize=(12, 9)):\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=len(residuals_or_outputs), figsize=figsize, sharey=True)\n",
        "  value_width = max(map(len, map(str, input_labels))) + 1\n",
        "\n",
        "  for i, (layer, ax) in enumerate(zip(residuals_or_outputs, axes)):\n",
        "    plt.sca(ax)\n",
        "    plt.pcolormesh(layer[0].T, vmin=0, vmax=1)\n",
        "    if i == 0:\n",
        "      add_residual_ticks(model, value_width=value_width)\n",
        "    plt.xticks(\n",
        "        np.arange(len(input_labels))+0.5,\n",
        "        input_labels,\n",
        "        rotation=90,\n",
        "        fontsize=20,\n",
        "    )\n",
        "    if add_input_layer and i == 0:\n",
        "      title = 'Input'\n",
        "    else:\n",
        "      layer_no = i - 1 if add_input_layer else i\n",
        "      layer_type = 'Attn' if layer_no % 2 == 0 else 'MLP'\n",
        "      title = f'{layer_type} {layer_no // 2 + 1}'\n",
        "    plt.title(title, fontsize=20)\n",
        "\n",
        "\n",
        "def plot_residuals_and_input(model, inputs, figsize=(12, 9)):\n",
        "  \"\"\"Applies model to inputs, and plots the residual stream at each layer.\"\"\"\n",
        "  model_out = model.apply(inputs)\n",
        "  residuals = np.concatenate([model_out.input_embeddings[None, ...],\n",
        "                              model_out.residuals], axis=0)\n",
        "  plot_computation_trace(\n",
        "      model=model,\n",
        "      input_labels=inputs,\n",
        "      residuals_or_outputs=residuals,\n",
        "      add_input_layer=True,\n",
        "      figsize=figsize)\n",
        "\n",
        "\n",
        "def plot_layer_outputs(model, inputs, figsize=(12, 9)):\n",
        "  \"\"\"Applies model to inputs, and plots the outputs of each layer.\"\"\"\n",
        "  model_out = model.apply(inputs)\n",
        "  plot_computation_trace(\n",
        "      model=model,\n",
        "      input_labels=inputs,\n",
        "      residuals_or_outputs=model_out.layer_outputs,\n",
        "      add_input_layer=False,\n",
        "      figsize=figsize)\n",
        "  \n",
        "#@title Plot residual stream\n",
        "plot_residuals_and_input(\n",
        "  model=assembled_model,\n",
        "  inputs=[\"bos\", 3, 4, 1],\n",
        "  figsize=(10, 9)\n",
        ")\n",
        "#@title Plot residual stream\n",
        "plot_residuals_and_input(\n",
        "  model=assembled_model,\n",
        "  inputs=[\"bos\", 3, 4, 1],\n",
        "  figsize=(10, 9)\n",
        ")\n",
        "#@title Plot layer outputs\n",
        "plot_layer_outputs(\n",
        "  model=assembled_model,\n",
        "  inputs = [\"bos\", 3, 4, 1],\n",
        "  figsize=(8, 9)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
